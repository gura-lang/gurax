#!/usr/bin/env gurax
import(ml)
import(ml.mnist)
import(gzip)
import(util.tester) {*}

db = ml.mnist.Database('../../sample/resource/mnist')
nTraining = 10

if (false) {
	model = `(((image + image2) / 2 |.| affineWeight + affineBias) |*| ml.Softmax())
	shapeImage = (1, db.nRows * db.nCols)
	affineWeight = @float(shapeImage[-1], db.nClasses)
	affineWeight.Inject(Random.NormalSeq(0, ml.Xavier(affineWeight.nRows)))
	affineBias = @float(1, affineWeight.nCols)
	affineBias.Inject(Random.NormalSeq(0, ml.Xavier(affineBias.nCols)))
} elsif (false) {
	model = `{
		t1 = (image |.| affineWeight1 + affineBias1) |*| ml.ReLU() |*| ml.Dropout(.5)
		t2 = t1 |.| affineWeight2 + affineBias2
		t3 = t2 |*| ml.Softmax()
	}
	shapeImage = (1, db.nRows * db.nCols)
	affineWeight1 = @float(shapeImage[-1], 100)
	affineWeight1.Inject(Random.NormalSeq(0, ml.Xavier(affineWeight1.nRows)))
	affineBias1 = @float(1, affineWeight1.nCols)
	affineBias1.Inject(Random.NormalSeq(0, ml.Xavier(affineBias1.nCols)))
	affineWeight2 = @float(affineWeight1.nCols, db.nClasses)
	affineWeight2.Inject(Random.NormalSeq(0, ml.Xavier(affineWeight2.nRows)))
	affineBias2 = @float(1, affineWeight2.nCols)
	affineBias2.Inject(Random.NormalSeq(0, ml.Xavier(affineBias2.nCols)))
} else {
	model = `{
		t1 = image |*| conv1 |*| ml.ReLU() |*| pool1 |*| flatten1
		t2 = (t1 |.| affineWeight1 + affineBias1) |*| ml.ReLU()
		t3 = (t2 |.| affineWeight2 + affineBias2)
		t4 = t3 |*| ml.Softmax()
	}
	shapeImage = (1, 1, db.nRows, db.nCols)
	conv1 = ml.Conv2d(nChannelsIn = 1, nRowsIn = db.nRows, nColsIn = db.nCols,
			nFilters = 30, nRowsFilter = 5, nColsFilter = 5, stride = 1, padding = 0)
	pool1 = ml.MaxPool2d(nRowsIn = conv1.nRowsOut, nColsIn = conv1.nColsOut, nRowsKernel = 2, nColsKernel = 2, stride = 2)
	flatten1 = ml.Reshape(1, conv1.nFilters * pool1.nRowsOut * pool1.nColsOut)
	affineWeight1 = @float(conv1.nFilters * pool1.nRowsOut * pool1.nColsOut, 100)
	affineBias1 = @float(affineWeight1.nCols)
	affineWeight2 = @float(affineWeight1.nCols, db.nClasses)
	affineBias2 = @float(affineWeight2.nCols)
	conv1.filter.Inject(Random.NormalSeq(0, ml.Xavier(conv1.nFilters)))
	conv1.bias.Inject(Random.NormalSeq(0, ml.Xavier(conv1.bias.nCols)))
	affineWeight1.Inject(Random.NormalSeq(0, ml.Xavier(affineWeight1.nRows)))
	affineBias1.Inject(Random.NormalSeq(0, ml.Xavier(affineBias1.nCols)))
	affineWeight2.Inject(Random.NormalSeq(0, ml.Xavier(affineWeight2.nRows)))
	affineBias2.Inject(Random.NormalSeq(0, ml.Xavier(affineBias2.nCols)))
}

scope {
	arrayImage = db.train.imageSet.ToArray(`float, flatten = true, numMax = 1)	// (nSamples, db.nRows * db.nCols)
	arrayLabel = db.train.labelSet.ToArray(`float, oneHot = true)				// (nSamples, db.nClasses)
	optimizer = ml.Optimizer.GradientDescent(0.01)
	//nSamples = arrayImage.nRows
	//nSamples = 10000
	nSamples = 100
	Printf('Training with %d samples [Image Size: %dx%d, Label Size: %d]\n', nSamples, db.nRows, db.nCols, db.nClasses)
	ml.Trainer(model, optimizer, `image) {|trainer|
		repeat (nTraining) {|iRepeat|
			repeat (nSamples) {|i|
				image = arrayImage[i].Reshape(shapeImage*)
				correct = arrayLabel[i].Reshape(1, nil)
				trainer.Train(correct, image)
			}
			Printf('#%d error=%g\n', iRepeat + 1, trainer.CalcMeanSquaredError(correct))
		}
		trainer.WriteProduct('product')
	}
}
