#!/usr/bin/env gurax
import(ml.mnist)

db = ml.mnist.Database('../../sample/resource/mnist')
nRows = db.train.imageSet.nRows
nCols = db.train.imageSet.nCols
nResults = 10
if (true) {
	weight = @float(nRows * nCols, nResults)
	weight.Inject(Random.NormalSeq(0, ml.Xavier(weight.shape[0])))
	bias = @float(1, nResults)
	bias.Inject(Random.NormalSeq(0, ml.Xavier(bias.shape[-1])))
	model = `((x |.| weight + bias) |*| ml.Softmax())
	//model = `((x |.| weight) |*| ml.Softmax())
} elsif (true) {
	nHidden = 100
	weight1 = @float(nRows * nCols, nHidden)
	weight2 = @float(nHidden, nResults)
	bias1 = @float(1, nHidden)
	bias2 = @float(1, nResults)
	weight1.Inject(Random.NormalSeq(0, ml.Xavier(weight1.shape[0])))
	weight2.Inject(Random.NormalSeq(0, ml.Xavier(weight2.shape[0])))
	bias1.Inject(Random.NormalSeq(0, ml.Xavier(bias1.shape[-1])))
	bias2.Inject(Random.NormalSeq(0, ml.Xavier(bias2.shape[-1])))
	//model = `(((x |.| weight1 + bias1) |*| ml.Sigmoid() |.| weight2 + bias2) |*| ml.Softmax())
	model = `(((x |.| weight1 + bias1) |*| ml.ReLU() |.| weight2 + bias2) |*| ml.Softmax())
} else {
	nFilters = 30
	nHidden = 100
	filters = @float(nFilters, 1, 5, 5)
	conv = ml.Conv2d(filters, stride = 1, padding = 0)
	[nRowsConv, nColsConv] = conv.CalcSizeOut(nRows, nCols)
	maxPool = ml.MaxPool2d(2, 2, stride = 2)
	[nRowsPool, nColsPool] = maxPool.CalcSizeOut(nRowsConv, nColsConv)
	flatten = ml.Reshape(nFilters * nRowsPool * nColsPool)
	bias1 = @float(nFilters)
	weight2 = @float(nFilters * nRowsPool * nColsPool, nHidden)
	bias2 = @float(nHidden)
	weight3 = @float(nHidden, nResults)
	bias3 = @float(nResults)
	model = `((((x |*| conv + bias1) |*| ml.ReLU() |*| maxPool |*| flatten \
				|.| weight2 + bias2) |*| ml.ReLU() \
				|.| weight3 + bias3) |*| ml.Softmax())
}

scope {
	nTraining = 100
	arrayImage = db.train.imageSet.ToArray(`float, flatten = true, numMax = 1)	// (nSamples, nRows * nCols)
	arrayLabel = db.train.labelSet.ToArray(`float, oneHot = true)				// (nSamples, nResults)
	optimizer = ml.Optimizer.GradientDescent(0.01)
	ml.Trainer(model, optimizer, `x) {|trainer|
		repeat (nTraining) {|iRepeat|
			repeat (1000) {|i|
				x = arrayImage[i].Reshape(1, nil)
				correct = arrayLabel[i].Reshape(1, nil)
				trainer.Train(correct, x)
			}
			Printf('#%d error=%g\n', iRepeat + 1, trainer.CalcMeanSquaredError(correct))
		}
	}
}
pattern = [' ', '.', ':', '#', '#']
scope {
	// evaluation
	arrayImage = db.test.imageSet.ToArray(`float, flatten = true, numMax = 1)	// (nSamples, nRows * nCols)
	arrayLabel = db.test.labelSet.ToArray(`float, oneHot = true)				// (nSamples, nResults)
	nCorrects = 0
	nTests = arrayImage.shape[0]
	repeat (nTests) {|i|
		x = arrayImage[i].Reshape(1, nil)
		t = arrayLabel[i].Reshape(1, nil)
		y = model.Eval()
		idxResult = y.ArgMax(-1, 0)
		idxCorrect = t.ArgMax(-1, 0)
		if (idxResult == idxCorrect) {
			//Printf(' "%d" .. correct with likelihood %.1f%%\n', idxResult, y[0, idxResult] * 100)
			nCorrects += 1
		} else {
			//arrayImage[i].ToList().Fold(db.test.imageSet.nCols) {|row| Printf('%s\n', pattern.Get(row * 4).Join())}
			//Printf(' "%d" .. wrong. correct is "%d"\n', idxResult, idxCorrect)
		}
	}
	Printf('accuracy: %d/%d (%.1f%%)\n', nCorrects, nTests, nCorrects / nTests * 100)
}
