#!/usr/bin/env gurax
//==============================================================================
// test-ml.gura
//==============================================================================
import(util.tester) {*}
import(ml)

Number.format@float = '%.3f'
a = @float([[-6, -1, 4], [-5, -1, -5], [-3, 2, 2]])
b = @float([[3, -1, 4], [1, 2, -5], [-2, 4, -4]])
correct = @float([[5, -2, -5], [5, -4, -2], [-6, 5, -3]])

PrintNodeHead(node as ml.Node) = {
	Printf('%s\n', node.typeName)
	Printf('  output     %s\n', node.output)
	Printf('  outputGrad %s\n', node.outputGrad)
}

PrintNodeUnary(node as ml.Node) = {
	Printf('%s\n', node.typeName)
	Printf('  input      %s\n', node.input)
	Printf('  output     %s\n', node.output)
	Printf('  outputGrad %s\n', node.outputGrad)
	Printf('  inputGrad  %s\n', node.inputGrad)
}

PrintNodeBinary(node as ml.Node) = {
	Printf('%s\n', node.typeName)
	Printf('  inputL     %s\n', node.inputL)
	Printf('  inputR     %s\n', node.inputR)
	Printf('  output     %s\n', node.output)
	Printf('  outputGrad %s\n', node.outputGrad)
	Printf('  inputGradL %s\n', node.inputGradL)
	Printf('  inputGradR %s\n', node.inputGradR)
}

TestCase('') {
	t = ml.Trainer(`(rtn = a + b), nil)
	t.Train(correct)
	PrintNodeHead(t[`a])
	PrintNodeHead(t[`b])
}
sys.Exit()

TestCase('Gear Node') {
	[
		`(rtn = a |*| ml.ReLU())
		`(rtn = a |*| ml.Sigmoid())
		`(rtn = a |*| ml.Softmax())
		`(rtn = a |*| ml.Tanh())
	].Each {|model|
		t = ml.Trainer(model, nil)
		t.Train(correct)
		PrintNodeUnary(t[`rtn])
	}
}

TestCase('Unary Node') {
	[
		`(rtn = -a)
	].Each {|model|
		t = ml.Trainer(model, nil)
		t.Train(correct)
		PrintNodeUnary(t[`rtn])
	}
}

TestCase('Binary Node') {
	[
		`(rtn = a + b)
		`(rtn = a - b)
		`(rtn = a * b)
		`(rtn = a |.| b)
	].Each {|model|
		t = ml.Trainer(model, nil)
		t.Train(correct)
		rtn = t[`rtn]
		PrintNodeBinary(t[`rtn])
	}
}
