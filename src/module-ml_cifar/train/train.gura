#!/usr/bin/env gurax
import(util.tester) {*}
import(ml)
import(conio.progress)

cifar = import(ml.cifar10)

db = cifar.Database('..')
optimizer = ml.Optimizer.GradientDescent(0.01)
superClassFlag = false
//------------------------------------------------------------------------------
nClasses = cond(superClassFlag, db.nClassesSuper, db.nClasses)
model = `{
	t0 = image |*| reshape
	t1 = t0 |*| conv1 |*| ml.ReLU() |*| pool1
	t2 = t1 |*| ml.Flatten(3)
	t3 = t2 |*| linear1 |*| ml.ReLU()
	t4 = t3 |*| linear2
	t5 = t4 |*| ml.Softmax()
}
reshape = ml.Reshape(nil, 3, db.nRows, db.nCols)
conv1 = ml.Conv2d(nFilters = 30, nRowsFilter = 3, nColsFilter = 3, stride = 1, padding = 0)
pool1 = ml.MaxPool2d(nRowsKernel = 2, nColsKernel = 2, stride = 2)
linear1 = ml.Linear(100)
linear2 = ml.Linear(nClasses)
//------------------------------------------------------------------------------
nEpochs = 100
batchSize = 16
nIterations = 1000
nSamples = cond(!nIterations || db.train.nSamples < batchSize * nIterations, db.train.nSamples, batchSize * nIterations)
Printf('Training with %d samples [Image Size:%dx%d, Classes:%d] -- Press Q to abort the process.\n', nSamples, db.nRows, db.nCols, nClasses)
ml.Trainer(model, optimizer, `image) {|trainer|
	abortFlag = false
	repeat (nEpochs) {|iEpoch|
		conio.progress.ProgressBar(20, nSamples, 'Epoch#%d ', iEpoch + 1) {|progressBar|
			db.train.EachBatch(batchSize, `float).Head(nIterations) {|sample, iIteration|
				result = cond(superClassFlag, sample.resultSuper, sample.result)
				trainer.Train(result, sample.input)
				if (progressBar.SetValue(iIteration * batchSize) && ml.KeyAbort(nil, Ord('q'))) {
					abortFlag = true
					break
				}
			}
			progressBar.Clear()
		}
		Printf('Epoch#%d error=%g\n', iEpoch + 1, trainer.CalcMeanSquaredError(result))
		abortFlag && break
	}
	trainer.CreateModule('recog')
}
