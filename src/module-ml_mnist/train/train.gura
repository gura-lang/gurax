#!/usr/bin/env gurax
import(util.tester) {*}
import(ml)
import(ml.mnist)
import(conio.progress)

db = ml.mnist.Database(path.Join(sys.dirBase, 'sample/resource/mnist'))
optimizer = ml.Optimizer.GradientDescent(0.01)
if (false) {
	model = `(input |*| reshape |*| linear |*| ml.Softmax())
	reshape = ml.Reshape(nil, db.nRows * db.nCols)
	linear = ml.Linear(db.nClasses)
} elsif (true) {
	model = `(input |*| reshape |*| linear1 |*| ml.ReLU() |*| linear2 |*| ml.Softmax())
	reshape = ml.Reshape(nil, db.nRows * db.nCols)
	linear1 = ml.Linear(100)
	linear2 = ml.Linear(db.nClasses)
} else {
	model = `{
		t0 = input |*| reshape
		t1 = t0 |*| conv1 |*| ml.ReLU() |*| pool1
		t2 = t1 |*| ml.Flatten(3)
		t3 = t2 |*| linear1 |*| ml.ReLU()
		t4 = t3 |*| linear2
		t5 = t4 |*| ml.Softmax()
	}
	reshape = ml.Reshape(nil, 1, db.nRows, db.nCols)
	conv1 = ml.Conv2d(nFilters = 30, nRowsFilter = 5, nColsFilter = 5, stride = 1, padding = 0)
	pool1 = ml.MaxPool2d(nRowsKernel = 2, nColsKernel = 2, stride = 2)
	linear1 = ml.Linear(100)
	linear2 = ml.Linear(db.nClasses)
}
//------------------------------------------------------------------------------
ml.Trainer(model, optimizer, `input).DoTraining(
	iteratorGenerator = &{db.train.EachBatch(32, `float)}
	nSamplesWhole = db.train.nSamples
	nEpochs = 20
	batchSize = 32
	nIterations = nil)
